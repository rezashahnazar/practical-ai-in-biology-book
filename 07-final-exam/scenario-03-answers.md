[← سناریو ۳: سوالات](./scenario-03-questions.md) | [سناریو ۴: پاسخنامه →](./scenario-04-answers.md)

# پاسخنامه سناریو ۳: مهندسی پروتئین با هوش مصنوعی مولد

در این بخش، پاسخ‌های تشریحی و کامل تمام سوالات سناریو ۳ ارائه می‌شود. هدف، نمایش گام‌به‌گام روش رسیدن به پاسخ صحیح با تحلیل دقیق مسئله، محاسبات لازم، و ارجاع به مفاهیم کلیدی کتاب است.

---

### **سوال ۱۱**

**پاسخ صحیح: ب) هدف مولد، به حداکثر رساندن خطای متمایزکننده است؛ یعنی تولید نمونه‌هایی که متمایزکننده را به اشتباه بیندازند.**

**مفاهیم کلیدی:** شبکه‌های تخاصمی مولد (GANs) (فصل ۲ و ۶)

**تحلیل:**

- آموزش GAN یک بازی با حاصل جمع صفر (zero-sum game) بین دو شبکه است.
- **متمایزکننده (Discriminator)** تلاش می‌کند تا خطای خود را به حداقل برساند (یعنی به درستی واقعی را از مصنوعی تشخیص دهد).
- **مولد (Generator)** برعکس، تلاش می‌کند تا نمونه‌هایی تولید کند که متمایزکننده را فریب دهند. موفقیت مولد در واقع به معنای شکست متمایزکننده است. بنابراین، مولد طوری آموزش داده می‌شود که **خطای متمایزکننده را به حداکثر برساند**.
- گزینه الف اشتباه است زیرا اهداف دو شبکه در تضاد هستند. گزینه ج نیز نادرست است زیرا گرچه هدف نهایی یادگیری توزیع داده است، اما این فرآیند مستقیماً از طریق به حداکثر رساندن خطای متمایزکننده هدایت می‌شود. گزینه د نیز به مشکل "حفظ کردن" اشاره دارد و هدف نهایی نیست.

---

### **سوال ۱۲**

**پاسخ صحیح: ج) فروپاشی مُد (Mode Collapse)؛ مولد یاد گرفته است که تعداد محدودی نمونه تولید کند که به خوبی متمایزکننده را فریب می‌دهند (کاهش هزینه مولد)، اما متمایزکننده به سرعت این نمونه‌های تکراری را شناسایی کرده و رد می‌کند.**

**مفاهیم کلیدی:** عیب‌یابی آموزش GAN، فروپاشی مد (فصل ۶)

**تحلیل:**

- سناریوی توصیف شده رفتار کلاسیک **فروپاشی مد** است.
- در ابتدا، هر دو Loss در حال نوسان و یادگیری هستند.
- ناگهان، **هزینه مولد (Generator Loss) به شدت کاهش می‌یابد**. این اتفاق زمانی می‌افتد که مولد یک یا چند نمونه "موفق" پیدا می‌کند که به خوبی متمایزکننده را فریب می‌دهند و سپس شروع به تولید انحصاری همان نمونه‌های محدود و غیرمتنوع می‌کند. چون در تولید این چند نمونه خاص مهارت پیدا کرده، خطای آن پایین می‌آید.
- همزمان، **هزینه متمایزکننده (Discriminator Loss) به شدت افزایش می‌یابد**. دلیل این است که متمایزکننده به سرعت یاد می‌گیرد که مولد فقط همین چند نوع نمونه تکراری را تولید می‌کند و بنابراین با اطمینان بسیار بالا آن‌ها را به عنوان "مصنوعی" شناسایی می‌کند. این تشخیص صحیح و با اطمینان بالا از دید متمایزکننده، به عنوان خطای بالا برای مولد تعبیر می‌شود و باعث افزایش شدید Loss متمایزکننده می‌گردد.

---

### **سوال ۱۳**

**پاسخ صحیح: ب) `Candidate_B` با امتیاز نهایی 88.50**

**مفاهیم کلیدی:** ارزیابی چندمعیاره، محاسبات وزنی (فصل ۵ و ۶)

**مراحل حل:**

امتیاز نهایی برای هر کاندیدا با استفاده از فرمول `Final_Score = (0.5 * TSI) + (0.3 * PLS) + (0.2 * SAS)` محاسبه می‌شود:

- **Candidate_A:**
  `Score = (0.5 * 92.5) + (0.3 * 88.0) + (0.2 * 75.0) = 46.25 + 26.4 + 15.0 = **87.65**`

- **Candidate_B:**
  `Score = (0.5 * 98.0) + (0.3 * 75.0) + (0.2 * 85.0) = 49.0 + 22.5 + 17.0 = **88.50**`

- **Candidate_C:**
  `Score = (0.5 * 85.0) + (0.3 * 95.0) + (0.2 * 70.0) = 42.5 + 28.5 + 14.0 = **85.00**`

با مقایسه امتیازات، `Candidate_B` بالاترین امتیاز را کسب می‌کند و به عنوان گزینه ارجح برای مرحله بعد انتخاب می‌شود.

---

### **سوال ۱۴**

**پاسخ صحیح: ب) چون RNNها دارای حافظه داخلی (حالت پنهان) هستند که به آن‌ها اجازه می‌دهد اطلاعات را از مراحل قبلی توالی به مراحل بعدی منتقل کنند و وابستگی‌های دوربرد را مدل کنند.**

**مفاهیم کلیدی:** معماری شبکه‌های عصبی، RNN در مقابل CNN (فصل ۶)

**تحلیل:**

- ویژگی کلیدی که RNNها را برای داده‌های ترتیبی (sequential) مانند زبان یا توالی پروتئین مناسب می‌سازد، **حلقه بازگشتی** آن‌هاست.
- در هر مرحله از پردازش توالی (مثلاً خواندن یک آمینواسید)، RNN نه تنها ورودی فعلی را در نظر می‌گیرد، بلکه یک **حالت پنهان (hidden state)** را نیز از مرحله قبل دریافت می‌کند. این حالت پنهان به عنوان نوعی "حافظه" عمل می‌کند و اطلاعات مربوط به تمام آمینواسیدهای قبلی را به صورت فشرده در خود نگه می‌دارد.
- این مکانیسم به RNN اجازه می‌دهد تا الگوها و وابستگی‌هایی را یاد بگیرد که بین عناصر بسیار دور از هم در توالی وجود دارند (مانند قواعد گرامری در یک جمله یا فعل و انفعالات بین آمینواسیدهای دور در یک پروتئین)، کاری که CNNها ذاتاً برای آن طراحی نشده‌اند. CNNها در یافتن الگوهای محلی و مستقل از موقعیت (local patterns) تخصص دارند.

---

### **سوال ۱۵**

**پاسخ صحیح: ج) انتخاب تیم از `Candidate_B` به `Candidate_C` تغییر می‌کند.**

**مفاهیم کلیدی:** تحلیل حساسیت، ارزیابی مدل (فصل ۵ و ۶)

**مراحل حل:**

امتیازات با فرمول جدید `Final_Score = (0.3 * TSI) + (0.5 * PLS) + (0.2 * SAS)` دوباره محاسبه می‌شوند:

- **Candidate_A:**
  `Score = (0.3 * 92.5) + (0.5 * 88.0) + (0.2 * 75.0) = 27.75 + 44.0 + 15.0 = **86.75**`

- **Candidate_B:**
  `Score = (0.3 * 98.0) + (0.5 * 75.0) + (0.2 * 85.0) = 29.4 + 37.5 + 17.0 = **83.9**`

- **Candidate_C:**
  `Score = (0.3 * 85.0) + (0.5 * 95.0) + (0.2 * 70.0) = 25.5 + 47.5 + 14.0 = **87.0**`

**تحلیل نتایج:**
در حالی که با وزن‌دهی اولیه (سوال ۱۳)، `Candidate_B` با امتیاز `88.50` برنده بود، با تغییر وزن‌ها برای اولویت دادن به معیار `PLS`، امتیازات تغییر می‌کنند. امتیاز `Candidate_C` به **87.0** می‌رسد و بالاترین امتیاز در میان کاندیداها می‌شود، در حالی که امتیاز `Candidate_B` به `83.9` کاهش می‌یابد.

بنابراین، این تحلیل حساسیت نشان می‌دهد که با تغییر در اولویت‌های استراتژیک، انتخاب نهایی تیم از `Candidate_B` به `Candidate_C` تغییر می‌کند.
