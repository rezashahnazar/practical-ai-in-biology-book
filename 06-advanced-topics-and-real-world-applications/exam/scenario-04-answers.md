[→ سناریو ۴: سوالات](./scenario-04-questions.md) | [بازگشت به آزمون فصل ششم](./index.md)

# پاسخنامه و تحلیل سناریو ۴: تحلیل سوگیری در هوش مصنوعی

---

### تحلیل و پاسخ سوال ۱

**پاسخ صحیح:** (ب) **سوگیری برچسب‌زنی (Labeling Bias / Proxy Discrimination)**

**تحلیل:**

- **سوگیری برچسب‌زنی** زمانی اتفاق می‌افتد که برچسب‌هایی که برای آموزش یک مدل استفاده می‌شوند، به طور دقیق واقعیت را منعکس نکنند. در این سناریو، ما می‌خواهیم "نیاز به مراقبت" را پیش‌بینی کنیم، اما از "هزینه مراقبت" به عنوان برچسب استفاده کرده‌ایم.
- **مشکل متغیر جایگزین (Proxy):** "هزینه" یک جایگزین ناقص برای "نیاز" است. همانطور که در سناریو توضیح داده شد، دسترسی به مراقبت‌های بهداشتی (و در نتیجه، هزینه‌های ایجاد شده) خود تحت تأثیر نابرابری‌های اجتماعی-اقتصادی است. افرادی که دسترسی کمتری دارند، هزینه کمتری نیز تولید می‌کنند، حتی اگر نیاز پزشکی بیشتری داشته باشند.
- **نتیجه:** مدل یاد می‌گیرد که به طور دقیق هزینه‌ها را پیش‌بینی کند، اما از آنجایی که هزینه‌ها به طور سیستماتیک نیاز واقعی گروه‌های کم‌برخوردار را کمتر از واقع نشان می‌دهند، مدل نیز همین سوگیری را یاد گرفته و بازتولید می‌کند. این پدیده که در آن یک متغیر جایگزین قانونی (مانند هزینه) منجر به تبعیض علیه یک گروه محافظت‌شده (مانند گروه‌های نژادی یا اقتصادی) می‌شود، **تبعیض از طریق جایگزین (Proxy Discrimination)** نامیده می‌شود.
- **چرا گزینه‌های دیگر غلط هستند؟**
  - **(الف) سوگیری نمونه‌گیری:** مشکل اینجا این نیست که داده‌های گروه کم‌برخوردار را نداریم، بلکه این است که داده‌هایی که از آن‌ها داریم (هزینه‌ها)، گمراه‌کننده ستند.
  - **(ج) سوگیری حذف:** ویژگی خاصی حذف نشده است. مشکل در خود متغیر هدف (برچسب) است.
  - **(د) سوگیری بیش‌برازش:** این یک مشکل عملکردی مدل است (ضعف در تعمیم)، در حالی که مشکل سناریوی ما یک مشکل بنیادی در تعریف مسئله و داده‌هاست. مدل ممکن است اصلاً دچار بیش‌برازش نباشد و به خوبی هزینه‌ها را پیش‌بینی کند.

---

### تحلیل و پاسخ سوال ۲

**پاسخ صحیح:** (ج) مدل به درستی کار می‌کند؛ این مدل دقیقاً همان چیزی را که از آن خواسته شده (پیش‌بینی هزینه‌ها) به خوبی انجام می‌دهد، اما هدف تعریف‌شده (پیش‌بینی هزینه‌ها) با هدف واقعی (پیش‌بینی نیاز به درمان) هم‌راستا نیست.

**تحلیل:**

- این نکته یکی از مهم‌ترین مفاهیم در اخلاق هوش مصنوعی است: **الگوریتم‌ها ذاتاً بد یا تبعیض‌آمیز نیستند.** آن‌ها ابزارهای بهینه‌سازی ریاضی هستند که سعی می‌کنند تابعی را که ما برایشان تعریف کرده‌ایم، به بهترین شکل ممکن بهینه کنند.
- **مشکل در تعریف هدف است، نه در اجرای آن.** در این سناریو، مدل هوش مصنوعی با موفقیت یاد گرفته است که هزینه‌های آینده را بر اساس هزینه‌های گذشته پیش‌بینی کند. از دیدگاه ریاضی، عملکرد آن صحیح است.
- **شکاف بین هدف تعریف‌شده و هدف واقعی (Alignment Problem):** مشکل اصلی این است که ما به عنوان انسان، یک "میان‌بر" ذهنی زده‌ایم و فرض کرده‌ایم که "هزینه" معادل "نیاز" است. الگوریتم این فرض اشتباه را نمی‌داند؛ او فقط تابعی را که به آن داده شده (پیش‌بینی هزینه) بهینه می‌کند. این عدم هم‌راستایی بین هدف فنی (Technical Objective) و هدف واقعی و ارزشی (Value-based Objective) ریشه اصلی این نوع سوگیری‌هاست.
- **چرا گزینه‌های دیگر غلط هستند؟**
  - **(الف):** این دیدگاه، مسئولیت را از طراحان سیستم به خود الگوریتم منتقل می‌کند که نادرست است. الگوریتم فقط ریاضیات را اجرا می‌کند.
  - **(ب):** کیفیت داده‌ها ممکن است خوب باشد و نویز زیادی هم نداشته باشند. مشکل در معنای خود داده‌هاست، نه کیفیت فنی آن‌ها.
  - **(د):** استفاده از یک مدل پیچیده‌تر، این مشکل بنیادی را حل نمی‌کند. یک شبکه عصبی عمیق هم اگر با همان داده‌های هزینه آموزش ببیند، همان سوگیری را یاد خواهد گرفت، شاید حتی با شدت بیشتری.

---

### تحلیل و پاسخ سوال ۳

**پاسخ صحیح:** (ب) تلاش برای یافتن یا ایجاد یک متغیر هدف (برچسب) بهتر که به "نیاز واقعی پزشکی" نزدیک‌تر باشد، مانند استفاده از نتایج آزمایش‌ها، تشخیص‌های پزشکی ثبت‌شده یا ارزیابی‌های مستقیم سلامت.

**تحلیل:**

- از آنجایی که ریشه مشکل در "برچسب" یا "متغیر هدف" است، مؤثرترین راه حل نیز باید مستقیماً خود این مشکل را هدف قرار دهد.
- **تغییر از هزینه به نیاز:** به جای استفاده از هزینه، باید به دنبال شاخص‌هایی باشیم که فارغ از وضعیت اقتصادی و دسترسی فرد، وضعیت سلامتی او را بهتر نشان دهند. برای مثال:
  - **سطح HbA1c** برای پیش‌بینی نیاز به مراقبت دیابت.
  - **تعداد دفعات بستری شدن در اورژانس** در سال گذشته.
  - **وجود بیماری‌های مزمن** ثبت‌شده در پرونده بیمار.
  - این شاخص‌ها به "نیاز" بیولوژیکی فرد نزدیک‌ترند تا "هزینه" اقتصادی.
- **چرا گزینه‌های دیگر غلط هستند؟**
  - **(الف):** جمع‌آوری داده‌های بیشتر از همان نوع معیوب، فقط مدل را در پیش‌بینی همان هدف اشتباه، قوی‌تر می‌کند و سوگیری را تقویت خواهد کرد.
  - **(ج):** حذف ویژگی محل زندگی ممکن است به طور سطحی جلوی تبعیض مستقیم را بگیرد، اما مدل به احتمال زیاد از طریق همبستگی‌های دیگر (مانند سطح درآمد، نوع شغل و...) همچنان همان سوگیری را یاد خواهد گرفت. این کار به "درمان علائم" شبیه است تا "درمان ریشه بیماری".
  - **(د):** تنظیم هایپرپارامترها دقت مدل را در پیش‌بینی _هزینه‌ها_ بهبود می‌بخشد، اما مشکل اصلی ما این است که _اساساً نباید هزینه‌ها را پیش‌بینی کنیم_. این کار مشکل عدم هم‌راستایی را حل نمی‌کند.
