[← سناریو ۱: سوالات](./scenario-01-questions.md) | [سناریو ۲: پاسخنامه →](./scenario-02-answers.md)

# پاسخنامه و تحلیل سناریو ۱: تحلیل مدل رگرسیون

---

### تحلیل و پاسخ سوال ۱

**پاسخ صحیح:** (ب) مدل دچار **بیش‌برازش (Overfitting)** شده است، زیرا عملکرد آن روی داده‌های آموزشی به طور قابل توجهی بهتر از داده‌های آزمایشی است.

**تحلیل:**

- **بیش‌برازش یا Overfitting** زمانی رخ می‌دهد که یک مدل، الگوهای موجود در داده‌های آموزشی را بیش از حد یاد می‌گیرد، تا جایی که به جای یادگیری روابط کلی، نویز و جزئیات تصادفی داده‌ها را نیز حفظ می‌کند.
- **نشانه کلیدی بیش‌برازش:** وجود اختلاف قابل توجه بین عملکرد مدل روی داده‌های آموزشی (Training) و داده‌های آزمایشی (Test). مدل روی داده‌هایی که با آن‌ها آموزش دیده عالی عمل می‌کند، اما در مواجهه با داده‌های جدید و دیده‌نشده، عملکرد ضعیفی دارد.
- **تحلیل نتایج جدول:**
  - **MAE:** خطای متوسط مطلق از 25.8 گرم در داده‌های آموزشی به 85.2 گرم در داده‌های آزمایشی افزایش یافته است (بیش از ۳ برابر).
  - **MSE:** خطای میانگین مربعات از 1150.5 به 9850.0 افزایش یافته است (بیش از ۸.۵ برابر).
  - **R-squared:** ضریب تعیین از 0.95 (بسیار عالی) به 0.82 (خوب، اما با افت محسوس) کاهش یافته است.
- این اختلاف فاحش در تمام معیارها نشان می‌دهد که مدل به جای یادگیری الگوهای عمومی، جزئیات داده‌های آموزشی را "حفظ" کرده و قادر به تعمیم (Generalize) دانش خود به داده‌های جدید نیست.
- **چرا گزینه‌های دیگر غلط هستند؟**
  - **(الف):** اگرچه R-squared 0.82 به خودی خود بد نیست، اما مقایسه آن با R-squared 0.95 آموزشی، مشکل اصلی (بیش‌برازش) را آشکار می‌کند. صرفاً نگاه کردن به عملکرد آزمایشی کافی نیست.
  - **(ج):** کم‌برازش (Underfitting) زمانی اتفاق می‌افتد که مدل حتی روی داده‌های آموزشی نیز عملکرد ضعیفی دارد. در اینجا، عملکرد آموزشی مدل بسیار بالاست (R²=0.95)، بنابراین مدل دچار کم‌برازش نیست.
  - **(د):** هیچ مدل رگرسیونی در دنیای واقعی دقت ۱۰۰٪ ندارد. R-squared 0.82 نشان می‌دهد که مدل هنوز ۸۲٪ از واریانس داده‌ها را توضیح می‌دهد و بنابراین کاملاً بی‌فایده نیست.

---

### تحلیل و پاسخ سوال ۲

**پاسخ صحیح:** (ب) به طور متوسط، پیش‌بینی‌های مدل ما در واقعیت حدود ۸۵.۲ گرم با وزن واقعی ماهی‌ها اختلاف دارد.

**تحلیل:**

- برای ارزیابی عملکرد واقعی مدل در دنیای خارج، باید به نتایج آن روی **داده‌های آزمایشی (Test Data)** نگاه کنیم، زیرا این داده‌ها شبیه‌ساز مواجهه مدل با نمونه‌های جدید و دیده‌نشده هستند.
- **MAE (Mean Absolute Error)** یا خطای متوسط مطلق، میانگین قدرمطلق اختلاف بین مقادیر پیش‌بینی‌شده و مقادیر واقعی را نشان می‌دهد. این معیار به دلیل سادگی در تفسیر (واحد آن همان واحد متغیر هدف است) برای ارائه گزارش به افراد غیرفنی مانند مدیران بسیار مناسب است.
- مقدار MAE روی داده‌های آزمایشی **85.2 گرم** است. این یعنی به طور میانگین، وزنی که مدل برای یک ماهی جدید پیش‌بینی می‌کند، ۸۵.۲ گرم با وزن واقعی آن تفاوت دارد.
- **چرا گزینه‌های دیگر غلط هستند؟**
  - **(الف):** مقدار ۲۵.۸ گرم مربوط به عملکرد روی داده‌های آموزشی است. گزارش این عدد به مدیرعامل، تصویری بیش از حد خوش‌بینانه و غیرواقعی از عملکرد مدل ارائه می‌دهد.
  - **(ج):** عدد ۹۸۵۰.۰ مقدار MSE است. واحد این معیار "گرم مربع" است و تفسیر مستقیم آن برای یک فرد غیرفنی دشوار است. همچنین، این عدد میانگین خطای پیش‌بینی نیست.
  - **(د):** این جمله تفسیر R-squared آموزشی است. در حالی که R-squared معیار مهمی است، اما به سوال مدیرعامل در مورد "مقدار متوسط خطا" به طور مستقیم پاسخ نمی‌دهد و علاوه بر آن، باید از مقدار آزمایشی آن (۸۲٪) استفاده کرد.

---

### تحلیل و پاسخ سوال ۳

**پاسخ صحیح:** (ب) مدل برای اکثر پیش‌بینی‌ها عملکرد خوبی دارد، اما گاهی اوقات خطاهای بسیار بزرگی (outliers) مرتکب می‌شود که توسط MSE جریمه سنگین‌تری دریافت می‌کنند.

**تحلیل:**

- **رابطه بین MAE و MSE:** هر دو معیار، خطا را اندازه‌گیری می‌کنند، اما **MSE (Mean Squared Error)** به دلیل استفاده از **توان دوم**، خطاهای بزرگ را بسیار بیشتر از خطاهای کوچک جریمه می‌کند.
  - فرض کنید دو خطا داریم: ۲ و ۱۰.
  - مجموع خطای مطلق (برای MAE): |۲| + |۱۰| = ۱۲
  - مجموع خطای مربع (برای MSE): ۲² + ۱۰² = ۴ + ۱۰۰ = ۱۰۴
  - همانطور که می‌بینید، خطای بزرگتر (۱۰) سهم بسیار بیشتری در مقدار نهایی MSE دارد.
- **تفسیر سناریو:**
  - در این مسئله، MSE (9850.0) به طور نامتناسبی بزرگتر از MAE² (حدود 7259) است.
  - اگر تمام خطاها تقریباً یکسان بودند، انتظار داشتیم که مقدار MSE به ریشه دوم MAE (یعنی RMSE) نزدیک باشد و در نتیجه MSE به MAE² نزدیک‌تر باشد.
  - این اختلاف بزرگ نشان می‌دهد که توزیع خطاها یکنواخت نیست. یعنی مدل برای بسیاری از نمونه‌ها خطای کمی تولید می‌کند، اما برای تعداد کمی از نمونه‌ها (که به آن‌ها **outliers** یا داده‌های پرت گفته می‌شود) خطاهای بسیار بزرگی مرتکب شده است. این خطاهای بزرگ، هنگام به توان دو رسیدن در محاسبه MSE، مقدار این معیار را به شدت بالا برده‌اند.
- **چرا گزینه‌های دیگر غلط هستند؟**
  - **(الف):** اگر مدل خطاهای کوچک و مداوم ایجاد می‌کرد، MSE و MAE² به یکدیگر بسیار نزدیک‌تر بودند.
  - **(ج):** این پدیده یک ویژگی ذاتی از نحوه محاسبه MSE است و مستقیماً به قابلیت اعتماد R-squared مربوط نمی‌شود.
  - **(د):** در حالی که نویز در داده‌ها می‌تواند علت این خطاهای بزرگ باشد، اما این اختلاف صرفاً یک پدیده آماری بی‌اهمیت نیست؛ بلکه یک سرنخ بسیار مهم در مورد **نحوه رفتار مدل** و توزیع خطاهای آن به ما می‌دهد.
