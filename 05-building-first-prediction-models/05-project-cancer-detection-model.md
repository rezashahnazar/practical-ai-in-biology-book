[â†’ Ø¨Ø®Ø´ Ûµ-Û´: Ù…Ø¯Ù„ Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø®ÙˆØ¨ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ](./04-model-evaluation-metrics.md) | [Ø¢Ø²Ù…ÙˆÙ† ÙØµÙ„ Ù¾Ù†Ø¬Ù… â†](./exam/index.md)

# ÙØµÙ„ Ûµ: Ø³Ø§Ø®Øª Ø§ÙˆÙ„ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: Ø§Ø² Ø¯Ø§Ø¯Ù‡ ØªØ§ ØªØ´Ø®ÛŒØµ

## Ø¨Ø®Ø´ Ûµ-Ûµ: Ù…Ø·Ø§Ù„Ø¹Ù‡ Ù…ÙˆØ±Ø¯ÛŒ: Ø³Ø§Ø®Øª Ø®Ø· Ù„ÙˆÙ„Ù‡ ØªØ´Ø®ÛŒØµ Ø³Ø±Ø·Ø§Ù† Ø§Ø² ØµÙØ± ØªØ§ ØµØ¯

**Ø®Ù„Ø§ØµÙ‡â€ŒÛŒ Ø§ØµÙ„ÛŒ:** Ø¯Ø± Ø§ÛŒÙ† Ù…Ø·Ø§Ù„Ø¹Ù‡â€ŒÛŒ Ù…ÙˆØ±Ø¯ÛŒØŒ ØªÙ…Ø§Ù… Ù…Ø±Ø§Ø­Ù„ ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÛŒ Ø¹Ù…Ù„ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø³Ø±Ø·Ø§Ù† Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù… Ù¾Ø²Ø´Ú©ÛŒ ØªØ§ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ØŒ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© Ø®Ø· Ù„ÙˆÙ„Ù‡â€ŒÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± Python Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

### Ù…Ù‚Ø¯Ù…Ù‡

ØªØ§ Ú©Ù†ÙˆÙ† Ø¨Ø§ Ù…Ø±Ø§Ø­Ù„ Ø§ØµÙ„ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù„Ù… Ø¯Ø§Ø¯Ù‡ Ø¢Ø´Ù†Ø§ Ø´Ø¯ÛŒÙ…: Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ØŒ ØªÙ‚Ø³ÛŒÙ… Ù…Ø¬Ù…ÙˆØ¹Ù‡ØŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ. Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ØŒ Ø§ÛŒÙ† Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø¯Ø± Google Colab Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³ÛŒÙ… ØªØ§ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø²Ø´Ú©ÛŒ Â«Ú©Ø«ÛŒÙÂ» Ø¨Ù‡ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø§Ø¯Ù‡ Ø´ÙˆÙ†Ø¯ØŒ Ø®Ø±ÙˆØ¬ÛŒ Ø¢Ù† Ú¯Ø²Ø§Ø±Ø´ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ø³Ø±Ø·Ø§Ù† Ø¨Ø§Ø´Ø¯.

### Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ú©Ø§Ù…Ù„ Ø¯Ø± Google Colab

Ú©Ø¯ Ø²ÛŒØ± Ù‡Ø± Ù‡ÙØª Ù…Ø±Ø­Ù„Ù‡â€ŒÛŒ Ú¯Ø±Ø¯Ø´ Ú©Ø§Ø± Ø±Ø§ Ø¨Ù‡ ØªÙØµÛŒÙ„ Ù¾ÛŒØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø±Ø§ÛŒ ØªØ³ØªØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª ÛŒÚ© Ø±Ø´ØªÙ‡ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ùˆ Ø´Ø§Ù…Ù„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ Ùˆ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ù†Ø§Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª Ú©Ù‡ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø´Ø¨ÛŒÙ‡ Ø¯Ù†ÛŒØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ù‡Ø³ØªÙ†Ø¯.

```python
# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Û±: ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
# ===================================================================
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    classification_report
)
import io

# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Û²: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ)
# ===================================================================
csv_data = \"\"\"Biomarker1,Biomarker2,TumorSize,Diagnosis,PatientAge,Metastasis
1.2,3.4,15.5,Positive,65,Yes
0.8,2.1,12.1,Negative,45,No
,3.9,18.2,Positive,72,yes
1.5,4.5,20.0,positive,68,Yes
0.5,1.9,10.3,negative,38,no
1.9,5.1,22.5,Positive,75,YES
1.1,3.2,NaN,Positive,59,Yes
0.7,2.5,11.5,Negative,41,No
\"\"\"
df = pd.read_csv(io.StringIO(csv_data))

# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Û³: Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# ===================================================================
# Û³.Û±: Ù¾Ø± Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ (NaN) Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³ØªÙˆÙ†
df[['Biomarker1','TumorSize']] = df[['Biomarker1','TumorSize']].apply(lambda col: col.fillna(col.mean()))  # [21]
# Û³.Û²: Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù†ÙˆØ´ØªÙ‡â€ŒÙ‡Ø§
df['Diagnosis']  = df['Diagnosis'].str.lower()
df['Metastasis'] = df['Metastasis'].str.lower()
# Û³.Û³: Ù†Ú¯Ø§Ø´Øª Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯
df['Diagnosis_numeric']   = df['Diagnosis'].apply(lambda x: 1 if x=='positive' else 0)
df['Metastasis_numeric']  = df['Metastasis'].apply(lambda x: 1 if x=='yes'      else 0)
df_cleaned = df.drop(['Diagnosis','Metastasis'], axis=1)

# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Û´: Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù‡Ø¯Ù
# ===================================================================
X = df_cleaned.drop('Diagnosis_numeric', axis=1)
y = df_cleaned['Diagnosis_numeric']

# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Ûµ: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø¢Ø²Ù…ÙˆÙ†
# ===================================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)  # [6]

# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Û¶: Ø³Ø§Ø®ØªØŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ (KNN Ø¨Ø§ K=3)
# ===================================================================
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
pred_knn = knn.predict(X_test)

# ===================================================================
# Ù…Ø±Ø­Ù„Ù‡ Û·: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ KNN
# ===================================================================
acc_knn = accuracy_score(y_test, pred_knn)
print(f"Ø¯Ù‚Øª Ù…Ø¯Ù„ KNN (K=3): {acc_knn*100:.2f}%")  # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 100% Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ[?]
cm_knn = confusion_matrix(y_test, pred_knn)
sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Ø³Ø§Ù„Ù…','Ø³Ø±Ø·Ø§Ù†ÛŒ'],
            yticklabels=['Ø³Ø§Ù„Ù…','Ø³Ø±Ø·Ø§Ù†ÛŒ'])
plt.title('Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ KNN')
plt.show()
print(classification_report(y_test, pred_knn, target_names=['Ø³Ø§Ù„Ù… (0)','Ø³Ø±Ø·Ø§Ù†ÛŒ (1)']))  # [5]

```

### Ù…Ø±ÙˆØ± Ú¯Ø±Ø¯Ø´ Ú©Ø§Ø±

Û±. **Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡:** Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø«ÛŒÙ Ø¨Ø§ `pandas.read_csv` Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯Ù‡ Ùˆ Ø´Ø§Ù…Ù„ `NaN` Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙ†ÛŒ Ú¯ÙˆÙ†Ø§Ú¯ÙˆÙ† Ø§Ø³Øª.  
Û². **Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ:** Ù¾Ø± Ú©Ø±Ø¯Ù† Ú¯Ù…Ø´Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³ØªÙˆÙ†Ø› ÛŒÚ©Ù†ÙˆØ§Ø®Øªâ€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú©Ø› Ùˆ Ù†Ú¯Ø§Ø´Øª Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±ÛŒØ§Ø¶ÛŒ[1].  
Û³. **Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ùˆ ØªÙ‚Ø³ÛŒÙ…:** `X` ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ `y` Ø¨Ø±Ú†Ø³Ø¨ ØªØ´Ø®ÛŒØµØ› Ø³Ù¾Ø³ ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ `train/test` Ø¨Ø± Ø§Ø³Ø§Ø³ `test_size=0.3`[2].  
Û´. **Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ:** Ù…Ø¯Ù„ KNN Ø¨Ø§ `n_neighbors=3` Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯[3].  
Ûµ. **Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:** Ø¯Ù‚ØªØŒ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯[4].

### ğŸ”¬ ØªÙ…Ø±ÛŒÙ† ØªØ­Ù„ÛŒÙ„ÛŒ: Ø¨Ù‡Ø¨ÙˆØ¯ Ø®Ø· Ù„ÙˆÙ„Ù‡

**ÙˆØ¸Ø§ÛŒÙ ØªØ¬Ø±Ø¨ÛŒ:**

1. **ØªØºÛŒÛŒØ± Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ± K:** Ù…Ù‚Ø¯Ø§Ø± `n_neighbors` Ø±Ø§ Ø¨Ù‡ 1 Ùˆ 5 ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯Ø› Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø«Ø¨Øª Ú©Ù†ÛŒØ¯.
2. **ØªØºÛŒÛŒØ± Ù†Ø³Ø¨Øª ØªÙ‚Ø³ÛŒÙ…:** `test_size` Ø±Ø§ Ø¨Ù‡ 0.2 ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯Ø› ØªØ£Ø«ÛŒØ± Ø¢Ù† Ø¨Ø± Ø¯Ù‚Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.
3. **Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†:** ÛŒÚ© Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ Ø¯ÛŒÚ¯Ø± (Ù…Ø§Ù†Ù†Ø¯ `LogisticRegression` ÛŒØ§ `DecisionTreeClassifier`) Ø±Ø§ Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Scikit-learn Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ØŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† KNN Ú©Ù†ÛŒØ¯ØŒ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯[5][6].

**Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù†Ù…ÙˆÙ†Ù‡**  
| Ù…Ø¯Ù„ | K | test*size | Ø¯Ù‚Øª |
|-----------------------|------|-----------|-------|
| KNN | 1 | 0.3 | 100% |
| KNN | 3 | 0.3 | 100% |
| KNN | 5 | 0.3 | 66.7% |
| KNN | 3 | 0.2 | 100% |
| LogisticRegression | â€“ | 0.3 | 100% |
| DecisionTreeClassifier| â€“ | 0.3 | 100% |  
*(Ù†Ù…ÙˆÙ†Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ)[ØŸ]\_

### ğŸ’¡ Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ

- **Ø®Ø· Ù„ÙˆÙ„Ù‡ Ø³Ø±ØªØ§Ø³Ø±ÛŒ:** Ù‡Ù…Ù‡ Ù…Ø±Ø§Ø­Ù„ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ§ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø± ÛŒÚ© Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡.
- **Ø§Ù‡Ù…ÛŒØª Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡:** Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡ Ùˆ Ù†Ø§Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒØŒ Ø¨Ø®Ø´ Ø¹Ù…Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ ØªØ´Ú©ÛŒÙ„ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
- **Ø¢Ø²Ù…Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ:** Ø¨Ù‡Ø¨ÙˆØ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ… Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù.
- **Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ:** Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ù‡ Ø´Ú©Ù„ Ø±Ø´ØªÙ‡ ÛŒØ§ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ø³Ø±ÛŒØ¹ Ú©Ø¯ Ù…ÙÛŒØ¯ Ø§Ø³Øª.

Ø§ÛŒÙ† ÙØµÙ„ Ù¾Ø§ÛŒÙ‡â€ŒÛŒ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ Ø´Ù…Ø§ Ø¯Ø± Ø¨ÛŒÙˆØ§Ù†ÙÙˆØ±Ù…Ø§ØªÛŒÚ© Ø±Ø§ ØªÙ‚ÙˆÛŒØª Ú©Ø±Ø¯. Ø§Ú©Ù†ÙˆÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø®Ø· Ù„ÙˆÙ„Ù‡â€ŒÛŒ Ú©Ø§Ù…Ù„ ØªØ´Ø®ÛŒØµ Ø³Ø±Ø·Ø§Ù† Ø±Ø§ Ø¨Ø³Ø§Ø²ÛŒØ¯ØŒ Ø§Ø¬Ø±Ø§ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯â€ŒØªØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ù†Ù…Ø§ÛŒÛŒØ¯.

---

## **Ù…Ù†Ø§Ø¨Ø¹**

[1] https://pandas.pydata.org/pandas-docs/version/2.0/reference/api/pandas.DataFrame.fillna.html
[2] https://www.geeksforgeeks.org/python/how-to-split-the-dataset-with-scikit-learns-train_test_split-function/
[3] https://scikit-learn.org/0.15/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
[4] https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html
[5] https://www.digitalocean.com/community/tutorials/logistic-regression-with-scikit-learn
[6] https://www.geeksforgeeks.org/building-and-implementing-decision-tree-classifiers-with-scikit-learn-a-comprehensive-guide/
[7] https://www.w3schools.com/python/pandas/ref_df_fillna.asp
[8] https://note.nkmk.me/en/python-pandas-nan-fillna/
[9] https://www.w3schools.com/python/python_ml_knn.asp
[10] https://www.youtube.com/watch?v=XWx8sjTkiuQ
[11] https://builtin.com/data-science/train-test-split
[12] https://www.projectpro.io/recipes/perform-logistic-regression-sklearn
[13] https://www.datacamp.com/tutorial/decision-tree-classification-python
[14] https://docs.vultr.com/python/third-party/pandas/DataFrame/fillna
[15] https://scikit-learn.org/0.21/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
[16] https://scikit-learn.org/0.15/modules/generated/sklearn.metrics.classification_report.html
[17] https://realpython.com/train-test-split-python-data/
[18] https://www.youtube.com/watch?v=5FdavD4eU4g
[19] https://scikit-learn.org/0.15/modules/generated/sklearn.tree.DecisionTreeClassifier.html
[20] https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
