# فصل ۵: ساخت اولین مدل‌های پیش‌بینی: از داده تا تشخیص

## بخش ۵-۵: مطالعه موردی: ساخت خط لوله تشخیص سرطان از صفر تا صد

[← بخش ۵-۴: مدل ما چقدر خوب کار می‌کند؟ معیارهای ارزیابی](./04-model-evaluation-metrics.md) | [آزمون فصل پنجم →](./exam/index.md)

تاکنون، ما قطعات مختلف یک پازل را دیده‌ایم: خواندن داده، پاک‌سازی، تقسیم، آموزش و ارزیابی. اما یک دانشمند داده‌ی واقعی، این مراحل را به عنوان یک "خط لوله" یا "گردش کار" (Workflow) یکپارچه می‌بیند. در این پروژه نهایی، ما نقش یک مهندس یادگیری ماشین را بازی می‌کنیم و تمام آموخته‌های خود را برای ساختن یک سیستم کامل تشخیص سرطان، از ابتدا تا انتها، به کار می‌گیریم. هدف ما این است که یک اسکریپت واحد بنویسیم که به طور خودکار داده‌های پزشکی کثیف را به عنوان ورودی بگیرد و یک گزارش کامل از عملکرد یک مدل پیش‌بینی‌کننده به عنوان خروجی تحویل دهد.

---

### اسکریپت کامل در Google Colab

کد زیر را می‌توانید به طور کامل در یک نوت‌بوک جدید Google Colab کپی و اجرا کنید. این کد تمام مراحل، از خواندن داده تا ارزیابی نهایی را شامل می‌شود.

```python
# ===================================================================
# مرحله ۱: وارد کردن کتابخانه‌های مورد نیاز
# ===================================================================
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import io

# ===================================================================
# مرحله ۲: آماده‌سازی داده‌ها (شبیه‌سازی فایل ورودی)
# ===================================================================
# در یک سناریوی واقعی، این داده‌ها از یک فایل CSV خوانده می‌شود.
# ما در اینجا آن را به صورت یک رشته شبیه‌سازی می‌کنیم تا کد قابل اجرا باشد.
csv_data = """
Biomarker1,Biomarker2,TumorSize,Diagnosis,PatientAge,Metastasis
1.2,3.4,15.5,Positive,65,Yes
0.8,2.1,12.1,Negative,45,No
,3.9,18.2,Positive,72,yes
1.5,4.5,20.0,positive,68,Yes
0.5,1.9,10.3,negative,38,no
1.9,5.1,22.5,Positive,75,YES
1.1,3.2,NaN,Positive,59,Yes
0.7,2.5,11.5,Negative,41,No
"""

# خواندن داده‌های شبیه‌سازی شده به یک DataFrame پانداز
df = pd.read_csv(io.StringIO(csv_data))
print("--- داده‌های خام اولیه ---")
print(df)
print("\n")


# ===================================================================
# مرحله ۳: پاک‌سازی و آماده‌سازی داده‌ها (Data Cleaning)
# ===================================================================

# ۳.۱: پر کردن مقادیر گمشده (NaN) با میانگین ستون
df['Biomarker1'].fillna(df['Biomarker1'].mean(), inplace=True)
df['TumorSize'].fillna(df['TumorSize'].mean(), inplace=True)

# ۳.۲: استاندارد کردن مقادیر ستون‌های متنی
df['Diagnosis'] = df['Diagnosis'].str.lower()
df['Metastasis'] = df['Metastasis'].str.lower()

# ۳.۳: تبدیل ستون‌های متنی به عددی
# Diagnosis: positive -> 1, negative -> 0
df['Diagnosis_numeric'] = df['Diagnosis'].apply(lambda x: 1 if x == 'positive' else 0)
# Metastasis: yes -> 1, no -> 0
df['Metastasis_numeric'] = df['Metastasis'].apply(lambda x: 1 if x == 'yes' else 0)

# حذف ستون‌های متنی اصلی
df_cleaned = df.drop(['Diagnosis', 'Metastasis'], axis=1)

print("--- داده‌های پاک‌سازی شده و عددی ---")
print(df_cleaned)
print("\n")


# ===================================================================
# مرحله ۴: جداسازی ویژگی‌ها (X) و هدف (y)
# ===================================================================
X = df_cleaned.drop('Diagnosis_numeric', axis=1)
y = df_cleaned['Diagnosis_numeric']

print("--- ویژگی‌ها (X) ---")
print(X.head())
print("\n--- هدف (y) ---")
print(y.head())
print("\n")


# ===================================================================
# مرحله ۵: تقسیم داده‌ها به مجموعه آموزش و آزمون
# ===================================================================
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
print(f"تعداد نمونه‌های آموزش: {len(X_train)}")
print(f"تعداد نمونه‌های آزمون: {len(X_test)}")
print("\n")


# ===================================================================
# مرحله ۶: ساخت، آموزش و پیش‌بینی با مدل KNN
# ===================================================================
# مقدار K=3 را انتخاب می‌کنیم
knn_model = KNeighborsClassifier(n_neighbors=3)

# آموزش مدل با داده‌های آموزشی
knn_model.fit(X_train, y_train)

# پیش‌بینی روی داده‌های آزمون
predictions = knn_model.predict(X_test)

print("--- پیش‌بینی‌های مدل روی داده‌های آزمون ---")
print("داده‌های واقعی:\t", y_test.values)
print("پیش‌بینی مدل:\t", predictions)
print("\n")


# ===================================================================
# مرحله ۷: ارزیابی عملکرد مدل
# ===================================================================
# ۷.۱: محاسبه دقت (Accuracy)
accuracy = accuracy_score(y_test, predictions)
print(f"--- ارزیابی مدل ---")
print(f"دقت کلی مدل: {accuracy * 100:.2f}%")

# ۷.۲: نمایش ماتریس درهم‌ریختگی (Confusion Matrix)
cm = confusion_matrix(y_test, predictions)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['سالم', 'سرطانی'], yticklabels=['سالم', 'سرطانی'])
plt.xlabel('پیش‌بینی مدل')
plt.ylabel('برچسب واقعی')
plt.title('ماتریس درهم‌ریختگی')
plt.show()

# ۷.۳: نمایش گزارش کامل طبقه‌بندی (Classification Report)
report = classification_report(y_test, predictions, target_names=['سالم (0)', 'سرطانی (1)'])
print("\n--- گزارش کامل طبقه‌بندی ---")
print(report)
```

### گردش کار را مرور کنیم

1.  **وارد کردن و آماده‌سازی داده (مراحل ۱ و ۲):** ما با وارد کردن کتابخانه‌های لازم شروع می‌کنیم و سپس یک مجموعه داده "کثیف" را شبیه‌سازی می‌کنیم. این مجموعه داده دارای مقادیر گمشده و فرمت‌های متنی ناهماهنگ است، دقیقاً مانند داده‌های دنیای واقعی.
2.  **پاک‌سازی (مرحله ۳):** در این مرحله، ما به طور سیستماتیک مشکلات داده‌ها را برطرف می‌کنیم: مقادیر گمشده را با میانگین پر می‌کنیم، متن‌ها را به حروف کوچک تبدیل می‌کنیم تا یکسان شوند، و در نهایت مقادیر متنی (مانند "positive" و "yes") را به فرمت عددی (1 و 0) تبدیل می‌کنیم که برای مدل‌های ریاضی قابل فهم باشد.
3.  **جداسازی و تقسیم (مراحل ۴ و ۵):** ما ستون هدف ("Diagnosis_numeric") را از ویژگی‌ها جدا کرده و سپس کل مجموعه داده را به دو بخش آموزش و آزمون تقسیم می‌کنیم تا بتوانیم مدل را به طور منصفانه ارزیابی کنیم.
4.  **آموزش و پیش‌بینی (مرحله ۶):** این قلب پروژه است. ما یک مدل `KNeighborsClassifier` را انتخاب کرده، آن را با داده‌های آموزشی (`X_train`, `y_train`) "fit" می‌کنیم و سپس از آن می‌خواهیم تا برچسب‌های داده‌های آزمون (`X_test`) را پیش‌بینی کند.
5.  **ارزیابی (مرحله ۷):** در نهایت، ما پیش‌بینی‌های مدل را با واقعیت (`y_test`) مقایسه می‌کنیم و با استفاده از معیارهای استاندارد مانند دقت، ماتریس درهم‌ریختگی و گزارش طبقه‌بندی، یک قضاوت کامل و دقیق در مورد عملکرد آن ارائه می‌دهیم.

---

### 🔬 تمرین تحلیلی: بهبود خط لوله

شما اکنون یک خط لوله (pipeline) کامل یادگیری ماشین دارید. آن را بهبود دهید.

**وظایف:**

1.  **تغییر هایپرپارامتر:** مقدار `n_neighbors` (همان `K`) را در مدل KNN تغییر دهید. آیا با `K=1` یا `K=5` نتایج بهتر یا بدتری می‌گیرید؟
2.  **تغییر نسبت تقسیم:** در `train_test_split`، مقدار `test_size` را از 0.3 به 0.2 تغییر دهید. این کار چه تأثیری بر عملکرد مدل دارد؟ آیا نمونه‌های آموزشی بیشتر همیشه بهتر است؟
3.  **چالش بزرگ:** به مستندات Scikit-learn بروید و یک الگوریتم طبقه‌بندی دیگر مانند `LogisticRegression` یا `DecisionTreeClassifier` را پیدا کنید. سعی کنید مدل KNN را با یکی از این مدل‌ها جایگزین کنید (کافی است چند خط کد را تغییر دهید). آیا عملکرد بهتری دارند؟

### 💡 نکات کلیدی این بخش

- **گردش کار سرتاسری (End-to-End Workflow):** یک پروژه علم داده شامل یک زنجیره منطقی از مراحل است: بارگذاری، پاک‌سازی، آماده‌سازی، جداسازی، تقسیم، آموزش، پیش‌بینی و ارزیابی.
- **شبیه‌سازی داده:** برای ساخت نمونه‌های اولیه و تست کد، می‌توان داده‌ها را به صورت رشته یا دیکشنری در خود اسکریپت ایجاد کرد.
- **اهمیت پاک‌سازی:** این مطالعه موردی نشان داد که بخش قابل توجهی از کد به مدیریت داده‌های ناقص و ناسازگار اختصاص دارد.
- **آزمایش و تکرار:** علم داده یک فرآیند ایستا نیست. بهترین نتایج با آزمایش هایپرپارامترهای مختلف، الگوریتم‌های گوناگون و روش‌های متفاوت آماده‌سازی داده به دست می‌آید.

این فصل پایه و اساس سفر شما در دنیای بیوانفورماتیک عملی را بنا نهاد. شما اکنون می‌توانید داده‌ها را پردازش کنید، مدل‌های پیش‌بینی‌کننده بسازید و عملکرد آنها را بسنجید.
