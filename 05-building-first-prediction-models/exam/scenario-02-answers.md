# آزمون فصل ۵: سناریو ۲ - پاسخنامه و تحلیل (ارزیابی صادقانه)

[← سناریو ۲: سوالات](./scenario-02-questions.md) | [سناریو ۳: سوالات →](./scenario-03-questions.md)

در این بخش، کد کامل برای اجرای هر دو روش ارزیابی (اشتباه و صحیح) ارائه شده و سپس تفاوت فاحش نتایج به دست آمده به تفصیل تحلیل می‌شود.

### کد کامل راه‌حل

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# =====================================================
# داده‌های آماده
# =====================================================
data = {
    'radius_mean': [17.99, 20.57, 19.69, 11.42, 20.29, 12.45],
    'texture_mean': [10.38, 17.77, 21.25, 20.38, 14.34, 15.7],
    'perimeter_mean': [122.8, 132.9, 130.0, 77.58, 135.1, 82.57],
    'area_mean': [1001.0, 1326.0, 1203.0, 386.1, 878.6, 477.1]
}
X = pd.DataFrame(data)
y = pd.Series([1, 1, 0, 0, 0, 1], name='diagnosis_numeric')

# =====================================================
# بخش الف: روش اشتباه (ارزیابی روی داده‌های آموزش)
# =====================================================
# ۱. نمونه‌سازی مدل
model_wrong = KNeighborsClassifier(n_neighbors=3)

# ۲. آموزش با تمام داده‌ها
model_wrong.fit(X, y)

# ۳. پیش‌بینی روی همان داده‌های آموزشی
predictions_wrong = model_wrong.predict(X)

# ۴. محاسبه و چاپ دقت
accuracy_wrong = accuracy_score(y, predictions_wrong)
print(f"دقت (روش اشتباه): {accuracy_wrong * 100:.2f}%")


# =====================================================
# بخش ب: روش صحیح (ارزیابی روی داده‌های آزمون)
# =====================================================
# ۱. تقسیم داده‌ها
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42
)

# ۲. نمونه‌سازی مدل جدید
model_correct = KNeighborsClassifier(n_neighbors=3)

# ۳. آموزش فقط با داده‌های آموزشی
model_correct.fit(X_train, y_train)

# ۴. پیش‌بینی روی داده‌های آزمون
predictions_correct = model_correct.predict(X_test)

# ۵. محاسبه و چاپ دقت
accuracy_correct = accuracy_score(y_test, predictions_correct)
print(f"دقت (روش صحیح): {accuracy_correct * 100:.2f}%")
```

### تحلیل و توضیح نتایج

چرا این دو عدد تا این حد با هم تفاوت دارند؟ پاسخ در یکی از بنیادی‌ترین مفاهیم یادگیری ماشین نهفته است: **تفاوت بین "حفظ کردن" و "یاد گرفتن"**.

#### روش اشتباه: یک امتحان با سوالات لو رفته

در روش اول، ما مدل را روی تمام داده‌های موجود آموزش دادیم و سپس دقیقاً همان داده‌ها را برای ارزیابی به آن دادیم. این کار مانند این است که به یک دانش‌آموز، پاسخنامه یک امتحان را بدهیم و بعد از او بخواهیم به همان سوالات پاسخ دهد. دانش‌آموز (مدل) به سادگی پاسخ‌ها را **حفظ کرده** است. دقت ۱۰۰٪ در این حالت، یک خوش‌بینی کاذب است و هیچ اطلاعاتی در مورد توانایی واقعی مدل برای حل مسائل جدید به ما نمی‌دهد. به این پدیده که مدل داده‌های آموزشی را بیش از حد خوب یاد می‌گیرد، **بیش‌برازش (Overfitting)** می‌گویند. مدل به جای یادگیری الگوی کلی، نویز و جزئیات بی‌اهمیت داده‌های آموزشی را نیز حفظ می‌کند.

#### روش صحیح: یک امتحان واقعی

در روش دوم، ما از قانون طلایی یادگیری ماشین پیروی کردیم. ما بخشی از داده‌ها را کنار گذاشتیم (`X_test`, `y_test`) و مدل در حین فرآیند آموزش (`.fit`) هرگز آنها را ندید. این مجموعه آزمون، شبیه‌سازی داده‌های جدید و دیده‌نشده در دنیای واقعی است. وقتی مدل را با این داده‌های جدید ارزیابی می‌کنیم، در واقع توانایی **تعمیم (Generalization)** آن را می‌سنجیم. هدف اصلی یک مدل یادگیری ماشین، تعمیم الگوهای یادگرفته شده به داده‌های جدید است.

دقت ۵۰٪ در این روش، هرچند پایین به نظر می‌رسد، اما یک معیار **صادقانه و واقع‌بینانه** از عملکرد این مدل ساده روی این مجموعه داده کوچک است. این عدد به ما می‌گوید که اگر یک بیمار جدید به ما مراجعه کند، این مدل احتمالاً با چه دقتی می‌تواند وضعیت او را پیش‌بینی کند. دقت ۱۰۰٪ روش اول، یک عدد بی‌ارزش و فریبنده است، در حالی که دقت ۵۰٪ روش دوم، یک معیار قابل اتکا برای تصمیم‌گیری‌های بعدی (مثلاً تلاش برای بهبود مدل) است.

**نتیجه‌گیری:** همیشه، همیشه و همیشه عملکرد مدل خود را بر روی داده‌هایی بسنجید که در فرآیند آموزش آن هیچ نقشی نداشته‌اند. این تنها راه برای درک توانایی واقعی مدل شماست.
