# آزمون فصل ۵: سناریو ۴ - پاسخنامه و تحلیل (بهینه‌سازی مدل)

[← سناریو ۴: سوالات](./scenario-04-questions.md) | [فصل ۶: مقدمه →](../06-advanced-topics-and-real-world-applications/00-introduction.md)

در این بخش، کد کامل برای آزمایش هایپرپارامتر `K` در مدل KNN ارائه شده و سپس تحلیل مفهومی نتایج و پاسخ به سوالات تشریح می‌شود.

### کد کامل راه‌حل

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import recall_score
from sklearn.datasets import load_breast_cancer

# =====================================================
# داده‌های آماده
# =====================================================
# بارگذاری مجموعه داده کامل از scikit-learn
cancer = load_breast_cancer()
X = pd.DataFrame(cancer.data, columns=cancer.feature_names)
y = pd.Series(cancer.target)

# برای سادگی، فقط از ۵ ویژگی استفاده می‌کنیم
features_to_use = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness']
X = X[features_to_use]

# =====================================================
# مرحله ۱: تقسیم داده‌ها
# =====================================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# =====================================================
# مرحله ۲: آموزش و ارزیابی سه مدل با K های مختلف
# =====================================================
# لیستی از مقادیر K برای آزمایش
k_values = [1, 5, 21]

print("--- بررسی تاثیر K بر روی Recall ---")
# حلقه برای تکرار روی هر مقدار K
for k in k_values:
    # a. نمونه‌سازی مدل با K فعلی
    model = KNeighborsClassifier(n_neighbors=k)

    # b. آموزش مدل
    model.fit(X_train, y_train)

    # c. پیش‌بینی روی مجموعه آزمون
    predictions = model.predict(X_test)

    # d. محاسبه Recall
    # ما از `pos_label=0` استفاده می‌کنیم چون در این دیتاست scikit-learn،
    # کلاس 0 نماینده بدخیم (Malignant) و کلاس 1 نماینده خوش‌خیم (Benign) است.
    # هدف ما شناسایی موارد بدخیم است.
    recall = recall_score(y_test, predictions, pos_label=0)

    # e. چاپ نتایج
    print(f"Recall for K={k}: {recall:.2f}")

```

_یک نکته مهم در مورد دیتاست `load_breast_cancer` در Scikit-learn: بر خلاف انتظار، در این دیتاست خاص، برچسب `0` نماینده "بدخیم" و `1` نماینده "خوش‌خیم" است. به همین دلیل در `recall_score` ما `pos_label=0` را مشخص می‌کنیم تا Recall را برای کلاس مثبت (بدخیم) محاسبه کنیم._

### تحلیل و توضیح نتایج

#### پاسخ به سوال ۱: بهترین مقدار K

بر اساس خروجی اسکریپت، هر دو مقدار **K=5** و **K=21** منجر به بالاترین امتیاز Recall (برابر با 0.95) شده‌اند. بنابراین، هر دو انتخاب‌های خوبی به نظر می‌رسند. در یک پروژه واقعی، برای انتخاب نهایی بین این دو، ممکن است از روش‌های پیشرفته‌تری مانند اعتبارسنجی متقابل (Cross-Validation) استفاده کنیم یا معیارهای دیگری مانند Precision را نیز در نظر بگیریم تا به یک توازن بهتر دست یابیم.

#### پاسخ به سوال ۲: تفکر مفهومی

##### چرا K=1 یک انتخاب پرخطر است؟

انتخاب `K=1` مدل را به شدت مستعد **بیش‌برازش (Overfitting)** می‌کند.

- **توضیح:** وقتی K=1 باشد، پیش‌بینی برای یک نقطه جدید صرفاً بر اساس برچسب **نزدیک‌ترین همسایه** آن در مجموعه آموزشی تعیین می‌شود. اگر این تک همسایه به صورت تصادفی یک نمونه نویزی، پرت (outlier) یا حتی با برچسب اشتباه باشد، پیش‌بینی مدل به راحتی به خطا می‌رود. این باعث می‌شود که مرز تصمیم‌گیری مدل بسیار پیچیده و "دندانه‌دار" شود و به جای یادگیری الگوی کلی داده‌ها، نویزهای مجموعه آموزشی را نیز "حفظ" کند.

##### چرا K بسیار بزرگ مشکل‌ساز است؟

انتخاب یک `K` بسیار بزرگ (مثلاً نزدیک به تعداد کل نمونه‌ها) مدل را به سمت **کم‌برازش (Underfitting)** سوق می‌دهد.

- **توضیح:** وقتی K بسیار بزرگ باشد، مدل برای هر پیش‌بینی به یک "اجماع عمومی" از تعداد بسیار زیادی از همسایه‌ها نگاه می‌کند. این کار باعث می‌شود که مرز تصمیم‌گیری بسیار "صاف" و ساده شود و مدل دیگر نتواند الگوهای کوچک، محلی و ظریف موجود در داده‌ها را تشخیص دهد. در واقع، مدل آنقدر کلی‌نگر می‌شود که دیگر قدرت تفکیک خود را از دست می‌دهد. برای مثال، اگر K برابر با تعداد کل نمونه‌های آموزشی باشد، مدل همیشه کلاسی را پیش‌بینی می‌کند که در کل مجموعه داده فراوان‌تر است، که عملاً یک مدل بی‌استفاده است.

**نتیجه‌گیری:** انتخاب `K` یک بده‌بستان (trade-off) بین یک مدل بیش از حد پیچیده (K کوچک) و یک مدل بیش از حد ساده (K بزرگ) است. هدف، یافتن یک نقطه بهینه در این بین است که بهترین توانایی تعمیم را روی داده‌های جدید داشته باشد. فرآیندی که ما انجام دادیم (آزمایش چند مقدار مختلف)، ساده‌ترین شکل **بهینه‌سازی هایپرپارامتر** است.
