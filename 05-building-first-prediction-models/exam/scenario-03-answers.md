# آزمون فصل ۵: سناریو ۳ - پاسخنامه و تحلیل (تفسیر عملکرد مدل)

[→ سناریو ۳: سوالات](./scenario-03-questions.md) | [سناریو ۴: سوالات ←](./scenario-04-questions.md)

در این بخش، پاسخ‌های تشریحی به سوالات سناریوی ۳ ارائه می‌شود. هدف این است که شما بتوانید اعداد و معیارها را به مفاهیم عملی در دنیای واقعی پزشکی ترجمه کنید.

### پاسخ به سوال ۱: تحلیل ماتریس درهم‌ریختگی

با تطبیق تعاریف با جدول ماتریس درهم‌ریختگی، به نتایج زیر می‌رسیم:

- **مثبت واقعی (TP):** تعداد نمونه‌هایی که واقعاً بدخیم (`1`) بوده و مدل نیز به درستی آنها را بدخیم (`1`) پیش‌بینی کرده است.
  - **مقدار: 55**
- **منفی کاذب (FN):** تعداد نمونه‌هایی که واقعاً بدخیم (`1`) بوده اما مدل به اشتباه آنها را خوش‌خیم (`0`) پیش‌بینی کرده است.
  - **مقدار: 8**
- **مثبت کاذب (FP):** تعداد نمونه‌هایی که واقعاً خوش‌خیم (`0`) بوده اما مدل به اشتباه آنها را بدخیم (`1`) پیش‌بینی کرده است.
  - **مقدار: 3**
- **منفی واقعی (TN):** تعداد نمونه‌هایی که واقعاً خوش‌خیم (`0`) بوده و مدل نیز به درستی آنها را خوش‌خیم (`0`) پیش‌بینی کرده است.
  - **مقدار: 105**

### پاسخ به سوال ۲: تحلیل گزارش طبقه‌بندی

مقادیر زیر مستقیماً از ردیف مربوط به کلاس "بدخیم (Class 1)" در گزارش طبقه‌بندی خوانده می‌شوند:

- **Recall (بازیابی یا حساسیت):** **0.87** (یا ۸۷٪)
- **Precision (دقت):** **0.95** (یا ۹۵٪)

**ارتباط با ماتریس درهم‌ریختگی:**
این اعداد را می‌توانیم با استفاده از مقادیر سوال ۱ نیز محاسبه کنیم تا ارتباط بین این دو جدول را بهتر درک کنیم:

- **فرمول Recall:** \( \frac{TP}{TP + FN} = \frac{55}{55 + 8} = \frac{55}{63} \approx 0.873 \)
- **فرمول Precision:** \( \frac{TP}{TP + FP} = \frac{55}{55 + 3} = \frac{55}{58} \approx 0.948 \)

همانطور که می‌بینید، نتایج کاملاً با گزارش طبقه‌بندی مطابقت دارند.

### پاسخ به سوال ۳: تفکر انتقادی و درک مفهومی

#### خطر کدام خطا بیشتر است؟

یک **منفی کاذب (False Negative)** به مراتب خطرناک‌تر است.

- **دلیل:** یک FN به این معناست که یک بیمار مبتلا به سرطان به اشتباه سالم تشخیص داده شده و به خانه فرستاده می‌شود. این می‌تواند منجر به تاخیر در درمان، پیشرفت بیماری و در نهایت به خطر افتادن جان بیمار شود. در مقابل، یک FP به این معناست که یک فرد سالم به اشتباه مشکوک به سرطان تشخیص داده شده و برای آزمایش‌های بیشتر (مانند نمونه‌برداری) فرستاده می‌شود. این حالت اگرچه باعث استرس و هزینه اضافی می‌شود، اما تهدید جانی مستقیم ندارد.

#### کدام معیار مهم‌تر است: Precision یا Recall؟

با توجه به خطر بالای FN، معیار **Recall** از اهمیت بسیار بالاتری برخوردار است.

- **دلیل:** Recall توانایی مدل در **شناسایی تمام موارد مثبت واقعی** را می‌سنجد. یک مدل با Recall بالا، مدلی است که تعداد کمی از بیماران واقعی را از دست می‌دهد (یعنی تعداد FN آن پایین است). در کاربردهای پزشکی مانند این، هدف اصلی ما این است که تا حد امکان هیچ بیماری را از قلم نیندازیم، حتی اگر به قیمت چند تشخیص مثبت کاذب (FP) تمام شود. بنابراین ما به دنبال حداکثر کردن Recall هستیم.

#### تحلیل نهایی عملکرد مدل

این مدل در **"اطمینان از اینکه تشخیص‌های بدخیم آن اشتباه نباشند"** بهتر عمل می‌کند تا در **"شناسایی اکثر بیماران واقعی"**.

- **توجیه:** **Precision** مدل برای کلاس بدخیم **(0.95)** به طور قابل توجهی بالاتر از **Recall** آن **(0.87)** است.
  - **Precision بالای 0.95** یعنی وقتی مدل می‌گوید یک تومور بدخیم است، ما می‌توانیم تا ۹۵٪ به این تشخیص اطمینان کنیم و احتمال اینکه این یک هشدار غلط (FP) باشد، کم است.
  - **Recall پایین‌تر 0.87** یعنی مدل تنها ۸۷٪ از کل بیماران سرطانی واقعی را شناسایی کرده و ۱۳٪ از آنها (۸ نفر) را از دست داده است (FN).

در نتیجه، این مدل یک مدل "محافظه‌کار" است. این مدل ترجیح می‌دهد که کمتر تشخیص "بدخیم" بدهد تا مبادا اشتباه کند، اما بهای این محافظه‌کاری، از دست دادن تعدادی از بیماران واقعی است. برای یک کاربرد بالینی واقعی، ما احتمالاً به دنبال مدلی با Recall بالاتر (مثلاً بالای ۰.۹۵) خواهیم بود، حتی اگر Precision آن کمی کاهش یابد.
