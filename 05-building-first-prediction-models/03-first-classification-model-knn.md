# فصل ۵: ساخت اولین مدل‌های پیش‌بینی: از داده تا تشخیص

## بخش ۵-۳: اولین مدل طبقه‌بندی: آموزش یک تصمیم‌گیرنده دیجیتال

[← بخش ۵-۲: هنر رام کردن داده‌ها: پاک‌سازی و آماده‌سازی](./02-art-of-data-wrangling.md) | [بخش ۵-۴: مدل ما چقدر خوب کار می‌کند؟ معیارهای ارزیابی →](./04-model-evaluation-metrics.md)

در بخش‌های قبل، ما داده‌هایمان را تمیز و آماده کردیم و آنها را به دو بخش ویژگی‌ها (`X`) و هدف (`y`) تقسیم کردیم. اکنون به هیجان‌انگیزترین بخش رسیده‌ایم: ساختن و آموزش دادن یک مدل هوش مصنوعی که بتواند بر اساس ویژگی‌های یک بیمار، تشخیص او را پیش‌بینی کند. این فرآیند، هسته اصلی یادگیری ماشین است.

### 🎯 مسئله محوری: چگونه می‌توانیم به یک ماشین "یاد بدهیم" که بین دو حالت (مثلاً سالم و بیمار) تمایز قائل شود، و چگونه مطمئن شویم که او واقعاً یاد گرفته و نه فقط "حفظ" کرده است؟

ما داده‌های تمیزی در اختیار داریم. اما چگونه می‌توانیم از این داده‌ها برای ساختن یک "مغز" مصنوعی استفاده کنیم که بتواند الگوهای پنهان مرتبط با یک بیماری را یاد بگیرد؟ الگوریتم یادگیری چگونه کار می‌کند؟ و از آن مهم‌تر، پس از آموزش، از کجا بدانیم که مدل ما یک "دانشمند" واقعی است که می‌تواند روی داده‌های جدید و دیده‌نشده نیز تصمیم درستی بگیرد، و نه یک "متقلب" که فقط پاسخ داده‌های آموزشی را از بر کرده است؟ در این بخش، ما با معرفی الگوریتم KNN و اصل حیاتی "تقسیم داده به آموزش و آزمون"، اولین مدل طبقه‌بندی خود را می‌سازیم و پایه‌های ارزیابی عادلانه آن را بنا می‌کنیم.

---

ما با یک مسئله **طبقه‌بندی (Classification)** روبرو هستیم: هدف ما این است که هر بیمار را در یکی از دو دسته (کلاس) "سالم" (0) یا "سرطانی" (1) قرار دهیم.

### قانون طلایی: تقسیم داده به دو بخش آموزش و آزمون

یک قانون بسیار مهم در یادگیری ماشین وجود دارد: **هرگز مدلی را با همان داده‌ای که با آن آموزش دیده است، ارزیابی نکنید.**

این کار مانند این است که به یک دانش‌آموز نمونه سوالات امتحانی را بدهید تا با آنها تمرین کند و بعد در امتحان نهایی، دقیقاً همان سوالات را از او بپرسید. نمره بالای او در این حالت هیچ ارزشی ندارد و نشان‌دهنده یادگیری واقعی او نیست.

برای جلوگیری از این مشکل، ما داده‌های خود را به دو مجموعه تقسیم می‌کنیم:

1.  **مجموعه آموزش (Training Set):** بخش بزرگتر داده‌ها (معمولاً ۷۰-۸۰٪) که مدل برای یادگیری الگوها از آن استفاده می‌کند.
2.  **مجموعه آزمون (Test Set):** بخش کوچکتر داده‌ها (معمولاً ۲۰-۳۰٪) که مدل در حین آموزش هرگز آنها را نمی‌بیند و ما از آن برای ارزیابی عملکرد واقعی مدل بر روی داده‌های جدید استفاده می‌کنیم.

کتابخانه Scikit-learn این کار را با یک تابع بسیار مفید به نام `train_test_split` برای ما انجام می‌دهد.

```python
# ادامه کد از بخش قبل...
# فرض می‌کنیم X و y از قبل آماده شده‌اند
from sklearn.model_selection import train_test_split

# تقسیم داده‌ها: 80% برای آموزش، 20% برای آزمون
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# random_state=42 یک عدد دلخواه برای اطمینان از این است که تقسیم‌بندی همیشه یکسان انجام شود.

print("اندازه مجموعه آموزش:", X_train.shape)
print("اندازه مجموعه آزمون:", X_test.shape)
```

### اولین الگوریتم ما: K-نزدیک‌ترین همسایه (K-Nearest Neighbors - KNN)

برای شروع، ما از یکی از ساده‌ترین و شهودی‌ترین الگوریتم‌های طبقه‌بندی استفاده می‌کنیم: KNN.

**منطق KNN:** برای پیش‌بینی برچسب یک نقطه داده جدید، به **K** تا از نزدیک‌ترین همسایه‌های آن در مجموعه آموزش نگاه کن و برچسبی که بیشترین تکرار را در میان آن همسایه‌ها دارد، به عنوان پیش‌بینی خود انتخاب کن.

> **آنالوژی:** تصور کنید شما در یک محله جدید هستید و نمی‌دانید که آیا باید برای یک تیم فوتبال محلی (مثلاً قرمز یا آبی) خوشحالی کنید. شما به ۵ (K=5) نفر از نزدیک‌ترین همسایه‌های خود نگاه می‌کنید. اگر ۳ نفر از آنها طرفدار تیم قرمز و ۲ نفر طرفدار تیم آبی باشند، شما احتمالاً نتیجه می‌گیرید که در یک محله قرمزنشین هستید و شما هم باید طرفدار تیم قرمز باشید!

### پیاده‌سازی با Scikit-learn: جادوی `fit` و `predict`

حالا بیایید با استفاده از API یکپارچه Scikit-learn، مدل KNN خود را بسازیم و آموزش دهیم.

```python
from sklearn.neighbors import KNeighborsClassifier

# ۱. انتخاب و نمونه‌سازی مدل
# ما K=3 را انتخاب می‌کنیم، یعنی مدل به 3 نزدیک‌ترین همسایه نگاه می‌کند
knn_model = KNeighborsClassifier(n_neighbors=3)

# ۲. آموزش مدل (فقط با داده‌های آموزش!)
knn_model.fit(X_train, y_train)

print("مدل با موفقیت آموزش دید!")

# ۳. پیش‌بینی بر روی داده‌های آزمون (که مدل هرگز ندیده است)
predictions = knn_model.predict(X_test)

print("\nداده‌های واقعی تست (y_test):")
print(y_test.values)

print("\nپیش‌بینی‌های مدل:")
print(predictions)
```

با اجرای این کد، شما اولین مدل یادگیری ماشین خود را آموزش داده‌اید! اما از کجا بفهمیم این پیش‌بینی‌ها خوب هستند؟ در بخش بعدی، ما با معیارهای ارزیابی مدل آشنا می‌شویم تا بتوانیم به این سوال به صورت کمی پاسخ دهیم.

---

### 🔬 تمرین تحلیلی: تاثیر پارامتر K

مدل KNN یک **هایپرپارامتر** کلیدی به نام `n_neighbors` (یا `K`) دارد. این عدد مشخص می‌کند که مدل برای تصمیم‌گیری به چند همسایه نگاه کند. انتخاب `K` می‌تواند تاثیر زیادی بر عملکرد مدل داشته باشد.

**وظیفه:**
کد بالا را کپی کرده و دو بار دیگر اجرا کنید:

1.  یک بار با `K=1` (`n_neighbors=1`). در این حالت، مدل فقط به نزدیک‌ترین همسایه خود نگاه می‌کند.
2.  یک بار با `K=5` (`n_neighbors=5`).

**سوالات برای فکر کردن:**

- آیا پیش‌بینی‌های مدل برای `K=1`، `K=3` و `K=5` متفاوت است؟
- به نظر شما `K` بسیار کوچک (مانند ۱) چه خطری دارد؟ (راهنمایی: به نویز و داده‌های پرت فکر کنید)
- `K` بسیار بزرگ (مثلاً به اندازه کل داده‌های آموزشی) چه مشکلی ایجاد می‌کند؟ (راهنمایی: به مرز تصمیم‌گیری فکر کنید)

### 💡 نکات کلیدی این بخش

- **طبقه‌بندی (Classification):** задачаی پیش‌بینی یک برچسب دسته‌ای (مانند "سالم" یا "بیمار").
- **تقسیم آموزش/آزمون:** حیاتی‌ترین اصل برای ارزیابی صادقانه مدل. مدل روی داده‌های آموزش یاد می‌گیرد و روی داده‌های آزمون (که قبلاً ندیده) سنجیده می‌شود.
- **تابع `train_test_split`:** ابزار استاندارد Scikit-learn برای انجام این تقسیم.
- **الگوریتم KNN:** یک الگوریتم ساده و شهودی که بر اساس "رای اکثریت" نزدیک‌ترین همسایگان تصمیم‌گیری می‌کند.
- **API یکپارچه Scikit-learn:** تمام مدل‌ها از الگوی `.fit()` برای آموزش و `.predict()` برای پیش‌بینی پیروی می‌کنند.

اکنون که می‌دانیم چگونه یک مدل را آموزش دهیم و پیش‌بینی کنیم، وقت آن است که یاد بگیریم چگونه عملکرد آن را به طور دقیق اندازه‌گیری کنیم.
