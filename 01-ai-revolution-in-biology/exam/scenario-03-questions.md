[→ سناریو ۲: سوالات](./scenario-02-questions.md) | [سناریو ۴: سوالات ←](./scenario-04-questions.md) | [پاسخنامه سناریو ۳](./scenario-03-answers.md)

# سناریو ۳: معضل اخلاقی استفاده دوگانه از هوش مصنوعی

### مقدمه سناریو

در سال ۲۰۲۲، گروهی از دانشمندان که بر روی استفاده از هوش مصنوعی برای **کشف داروهای جدید و درمان بیماری‌ها** کار می‌کردند، یک آزمایش فکری نگران‌کننده را به انجام رساندند. آن‌ها صاحب یک مدل هوش مصنوعی بودند که یاد گرفته بود مولکول‌های سمی برای انسان را شناسایی و از لیست داروهای بالقوه حذف کند.

محققان تصمیم گرفتند هدف مدل را معکوس کنند. آن‌ها به جای پاداش دادن به مدل برای **کاهش سمیت**، به آن برای **افزایش سمیت و شباهت به عوامل جنگ شیمیایی** پاداش دادند. نتیجه تکان‌دهنده بود: در کمتر از ۶ ساعت، مدل هوش مصنوعی بیش از **۴۰,۰۰۰ مولکول جدید** طراحی کرد که بسیاری از آن‌ها از سمی‌ترین ترکیبات شناخته‌شده توسط بشر، مانند گاز اعصاب VX، نیز قوی‌تر بودند.

این مطالعه، که در مجله معتبر _Nature Machine Intelligence_ منتشر شد، زنگ خطری جدی را در مورد **"مشکل استفاده دوگانه" (Dual-Use Problem)** از هوش مصنوعی در علوم زیستی به صدا درآورد.

### سوالات

**۱. بر اساس متن، "مشکل استفاده دوگانه" در زمینه هوش مصنوعی به چه معناست؟**

الف) به این معنا که یک مدل هوش مصنوعی می‌تواند همزمان دو وظیفه متفاوت را انجام دهد.
ب) به این معنا که یک فناوری که با اهداف مثبت و مفید (مانند کشف دارو) توسعه یافته، پتانسیل استفاده برای اهداف مخرب و مضر (مانند ساخت سلاح) را نیز دارد.
ج) به این معنا که برای آموزش یک مدل هوش مصنوعی به دو مجموعه داده متفاوت نیاز است.
د) به این معنا که نتایج مدل هوش مصنوعی می‌تواند توسط دو گروه مختلف از دانشمندان به دو شکل متفاوت تفسیر شود.

**۲. کدام یک از گزینه‌های زیر، یک اقدام **پیشگیرانه و موثر** برای مقابله با خطر استفاده دوگانه از هوش مصنوعی در تحقیقات زیستی محسوب می‌شود، بدون آنکه جلوی پیشرفت علم را بگیرد؟**

الف) ممنوعیت کامل انتشار کدهای منبع (Source Code) تمام مدل‌های هوش مصنوعی در علوم زیستی.
ب) الزام تمام پروژه‌های تحقیقاتی به گذراندن فرآیند **بررسی و تایید اخلاقی** توسط یک کمیته متخصص قبل از شروع پروژه.
ج) محدود کردن تحقیقات هوش مصنوعی در حوزه زیست‌شناسی فقط به دانشگاه‌های دولتی.
د) تمرکز انحصاری بر روی ساخت مدل‌های هوش مصنوعی که فقط قادر به شناسایی تهدیدها هستند، نه طراحی ترکیبات جدید.

**۳. عبارت زیر صحیح است یا غلط؟**

"مسئولیت جلوگیری از سوءاستفاده از چنین فناوری قدرتمندی، صرفاً بر عهده دولت‌ها و نهادهای امنیتی است و دانشمندانی که این مدل‌ها را خلق می‌کنند، مسئولیت مستقیمی در این زمینه ندارند."

الف) صحیح
ب) غلط
