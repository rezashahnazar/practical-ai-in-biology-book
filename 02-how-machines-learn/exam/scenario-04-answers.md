[← پاسخنامه سناریو ۳](./scenario-03-answers.md) | [مقدمه فصل سوم →](../03-art-of-pattern-recognition/00-introduction.md)

## سناریوی ۴: پاسخنامه و تحلیل سوالات

### پاسخ سوال ۱

**پاسخ صحیح: گزینه الف (صحیح)**

**تحلیل:**

این گزاره صحیح است. در این مسئله، ما به دنبال تخصیص یکی از **دو** کلاس ممکن به هر توالی DNA هستیم: "پروموتر" یا "غیر-پروموتر". وظیفه‌ای که در آن تنها دو کلاس هدف وجود دارد، **طبقه‌بندی باینری (Binary Classification)** نامیده می‌شود. این ساده‌ترین نوع مسئله طبقه‌بندی است. اگر بیش از دو کلاس داشتیم (مانند سناریوی ۱ که ۱۰ جایگاه سلولی داشت)، مسئله از نوع طبقه‌بندی چندکلاسه (multi-class) می‌بود.

### پاسخ سوال ۲

**پاسخ صحیح: گزینه د (۲۲۸)**

**تحلیل:**

برای محاسبه ابعاد ورودی نهایی، باید فرآیند کدگذاری One-Hot را در نظر بگیریم:

1.  هر نوکلئوتید منفرد به یک بردار با **۴** عنصر عددی تبدیل می‌شود (مثلاً A به `[1, 0, 0, 0]`).
2.  توالی DNA ما دارای **۵۷** نوکلئوتید است.
3.  وقتی کل توالی را کدگذاری می‌کنیم، ما در واقع ۵۷ تا از این بردارهای ۴ عنصری را به دنبال هم قرار می‌دهیم.

بنابراین، تعداد کل عناصر عددی در بردار ورودی نهایی برابر است با طول توالی ضربدر طول بردار کدگذاری هر نوکلئوتید:

تعداد کل عناصر = (طول توالی) × (تعداد نوکلئوتیدهای ممکن) = ۵۷ × ۴ = **۲۲۸**

این بردار ۲۲۸ بعدی (یا ماتریس ۵۷x۴) به عنوان ورودی به لایه اول شبکه عصبی داده می‌شود و لایه ورودی شبکه باید ۲۲۸ نورون داشته باشد.

### پاسخ سوال ۳

**پاسخ صحیح: گزینه ب (۱ نورون، تابع فعال‌سازی Sigmoid)**

**تحلیل:**

این ترکیب، معماری استاندارد و کارآمد برای لایه خروجی در مسائل طبقه‌بندی باینری است.

- **تعداد نورون‌ها:** ما تنها به **۱ نورون** در لایه خروجی نیاز داریم. خروجی این نورون یک مقدار عددی بین ۰ و ۱ خواهد بود که می‌توان آن را به عنوان احتمال تعلق نمونه به "کلاس مثبت" (مثلاً کلاس "پروموتر") تفسیر کرد. اگر خروجی p باشد، احتمال تعلق به کلاس منفی (غیر-پروموتر) به طور خودکار p-۱ خواهد بود.
- **تابع فعال‌سازی (Sigmoid):** تابع سیگموئید هر مقدار ورودی حقیقی را به یک مقدار در محدوده (۰, ۱) نگاشت می‌کند. این ویژگی آن را برای تولید خروجی احتمالی در طبقه‌بندی باینری ایده‌آل می‌سازد.

**چرا گزینه‌های دیگر نامناسب هستند؟**

- **الف (۲ نورون، Softmax):** اگرچه این روش نیز کار می‌کند و معادل ریاضیاتی روش سیگموئید است، اما استفاده از آن برای طبقه‌بندی باینری افزونگی (redundant) دارد و پیچیدگی غیرضروری به مدل اضافه می‌کند. این معماری برای طبقه‌بندی چندکلاسه (با بیش از ۲ کلاس) استاندارد است.
- **ج و د:** توابع ReLU و Tanh برای لایه خروجی در مسائل طبقه‌بندی مناسب نیستند زیرا خروجی آن‌ها به صورت احتمال تفسیر نمی‌شود. ReLU مقادیر نامحدود مثبت و Tanh مقادیر بین -۱ و ۱ تولید می‌کند.

### پاسخ سوال ۴

**پاسخ صحیح: گزینه الف (مدل با اطمینان ۸۵٪ پیش‌بینی می‌کند که توالی یک پروموتر است.)**

**تحلیل:**

در معماری استاندارد طبقه‌بندی باینری (با ۱ نورون خروجی و تابع سیگموئید)، خروجی مدل (در اینجا 0.85) به عنوان احتمال تعلق نمونه به **کلاس مثبت** تفسیر می‌شود. ما معمولاً کلاس "مورد علاقه" یا "هدف" را به عنوان کلاس مثبت در نظر می‌گیریم. در این سناریو، هدف پیدا کردن پروموترهاست، بنابراین کلاس "پروموتر" کلاس مثبت (معمولاً با برچسب ۱) و "غیر-پروموتر" کلاس منفی (با برچسب ۰) است.

**آستانه تصمیم‌گیری (Decision Threshold):**

ما از یک آستانه (معمولاً 0.5) برای تبدیل این احتمال به یک تصمیم قطعی استفاده می‌کنیم:

- اگر خروجی مدل **بیشتر** از آستانه باشد (0.85 > 0.5)، نمونه را به عنوان کلاس **مثبت (پروموتر)** طبقه‌بندی می‌کنیم.
- اگر خروجی مدل **کمتر** از آستانه باشد، نمونه را به عنوان کلاس **منفی (غیر-پروموتر)** طبقه‌بندی می‌کنیم.

بنابراین، خروجی 0.85 به این معنی است که مدل با احتمال ۸۵٪ پیش‌بینی می‌کند که توالی ورودی یک پروموتر است و چون این مقدار از آستانه 0.5 بیشتر است، پیش‌بینی نهایی مدل "پروموتر" خواهد بود.
